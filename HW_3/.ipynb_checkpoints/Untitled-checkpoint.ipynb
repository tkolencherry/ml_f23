{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9614bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25007ce3",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "* Drop tweet ID and timestamp\n",
    "* Change letters to all lowercase\n",
    "* Drop '#' and '@'\n",
    "* Drop URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ed3571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585891883953496066</td>\n",
       "      <td>Wed Apr 08 19:48:05 +0000 2015</td>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585876545266286592</td>\n",
       "      <td>Wed Apr 08 18:47:08 +0000 2015</td>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585861945535791106</td>\n",
       "      <td>Wed Apr 08 17:49:07 +0000 2015</td>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585859917350731777</td>\n",
       "      <td>Wed Apr 08 17:41:03 +0000 2015</td>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585844465199407104</td>\n",
       "      <td>Wed Apr 08 16:39:39 +0000 2015</td>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                               1  \\\n",
       "0  585891883953496066  Wed Apr 08 19:48:05 +0000 2015   \n",
       "1  585876545266286592  Wed Apr 08 18:47:08 +0000 2015   \n",
       "2  585861945535791106  Wed Apr 08 17:49:07 +0000 2015   \n",
       "3  585859917350731777  Wed Apr 08 17:41:03 +0000 2015   \n",
       "4  585844465199407104  Wed Apr 08 16:39:39 +0000 2015   \n",
       "\n",
       "                                                   2  \n",
       "0  Are you a member of the network? Sign up here ...  \n",
       "1  What is palliative care like in India? One GP ...  \n",
       "2  Most viewed this week: I loved being a midwife...  \n",
       "3  How can technology improve mental health waiti...  \n",
       "4  In case you missed it: Why the #NHS shouldn’t ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the tweets from the various text files. Since we don't need to build our model based on originating news outlet, I combined the tweets into one text file\n",
    "path = r'C:\\Users\\teris\\ml_f23\\HW_3\\tweets.txt'\n",
    "tweets = pd.read_table(path, sep = \"|\", header = None, on_bad_lines='skip')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "481dea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  Are you a member of the network? Sign up here ...\n",
       "1  What is palliative care like in India? One GP ...\n",
       "2  Most viewed this week: I loved being a midwife...\n",
       "3  How can technology improve mental health waiti...\n",
       "4  In case you missed it: Why the #NHS shouldn’t ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now delete out the tweet id and timestamp\n",
    "retweets = tweets.drop(columns = [0,1]).drop_duplicates()\n",
    "retweets = retweets.rename(columns = {0:'ID', 2:'Tweet'})\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b57fe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets['Clean'] = retweets.apply(lambda row: str(row['Tweet']).lower(),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(\"@[A-Za-z0-9_]+\",\"\", str(row['Clean'])),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(\"#\",\"\", str(row['Clean'])),axis=1) #we still want to keep the tagnames, just not the hashtag\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(r\"http\\S+\",\"\", row['Clean']),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(r\"www.\\S+\",\"\", row['Clean']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb29d9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you a member of the network? Sign up here for free: https://register.theguardian.com/healthcare-professionals/ #NHS #healthcare\n",
      "are you a member of the network? sign up here for free:  nhs healthcare\n"
     ]
    }
   ],
   "source": [
    "print(retweets.Tweet[0])\n",
    "print(retweets.Clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f64aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'you', 'a', 'member', 'of', 'the', 'network?', 'sign', 'up', 'here', 'for', 'free:', 'nhs', 'healthcare']\n"
     ]
    }
   ],
   "source": [
    "#to make my life easier, I'm going to go ahead and pre-process the tweets to form their specific bag of words \n",
    "retweets['Clean'] = retweets.apply(lambda row: row['Clean'].split(),axis=1)\n",
    "print(retweets.Clean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584f3a7",
   "metadata": {},
   "source": [
    "## KMeans Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "21573888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "      <td>[are, you, a, member, of, the, network?, sign,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "      <td>[what, is, palliative, care, like, in, india?,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "      <td>[most, viewed, this, week:, i, loved, being, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "      <td>[how, can, technology, improve, mental, health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "      <td>[in, case, you, missed, it:, why, the, nhs, sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  Are you a member of the network? Sign up here ...   \n",
       "1  What is palliative care like in India? One GP ...   \n",
       "2  Most viewed this week: I loved being a midwife...   \n",
       "3  How can technology improve mental health waiti...   \n",
       "4  In case you missed it: Why the #NHS shouldn’t ...   \n",
       "\n",
       "                                               Clean  \n",
       "0  [are, you, a, member, of, the, network?, sign,...  \n",
       "1  [what, is, palliative, care, like, in, india?,...  \n",
       "2  [most, viewed, this, week:, i, loved, being, a...  \n",
       "3  [how, can, technology, improve, mental, health...  \n",
       "4  [in, case, you, missed, it:, why, the, nhs, sh...  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_short = retweets.head(25)\n",
    "retweets_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e722d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn it into a class to make it all easier \n",
    "class kmeansclusters():\n",
    "    def __init__(self, tweets, k): \n",
    "        self.tweets = tweets\n",
    "        self.n = len(tweets)\n",
    "        self.k = k\n",
    "        self.distMatrix = {}\n",
    "        \n",
    "        self.clusters = {}\n",
    "        self.reverse_cluster = {}\n",
    "        \n",
    "        self.init_centers = self.centers_setup() #pick the random centers\n",
    "        #Set up the Jaccard matrix and the Initial Clusters\n",
    "        self.cluster_setup()\n",
    "        self.jaccard_matrix()\n",
    "        \n",
    "        self.iteration_threshold = 1000\n",
    "        \n",
    "    #f(x): jaccard_dist\n",
    "    #PURPOSE: find the jaccard distance ( 1 - jaccard similarity) between two sets of words\n",
    "    #OUTPUT: returns a float value between 0 and 1. The closer to 1, the further apart the sets are\n",
    "    def jaccard_dist(self, setA, setB): \n",
    "        setA = set(setA) #intersection and union won't work on lists, must be set format\n",
    "        setB = set(setB)\n",
    "        intersection_AB = len(setA.intersection(setB))\n",
    "        union_AB = len(setA.union(setB))\n",
    "        return 1 - (intersection_AB/union_AB)\n",
    "    \n",
    "    #f(x): jaccard_matrix\n",
    "    #PURPOSE: create a distance matrix where each tweet is a row and a column. This matrix will help us keep track of which two clusters are closest.\n",
    "            # This idea is similar to the matrices we used to show which nodes are connected in graphs.\n",
    "    #OUTPUT: none - the goal is simply to initialize the matrix\n",
    "    def jaccard_matrix (self):\n",
    "        for ptA in self.tweets.Clean.index: \n",
    "            self.distMatrix[ptA] = {}\n",
    "            setA = self.tweets.Clean[ptA]\n",
    "            for ptB in self.tweets.Clean.index: \n",
    "                if ptB not in self.distMatrix: \n",
    "                    self.distMatrix[ptB] = {}\n",
    "                setB = self.tweets.Clean[ptB]\n",
    "                dist_AB = self.jaccard_dist(setA, setB)\n",
    "                self.distMatrix[ptA][ptB] = dist_AB\n",
    "                self.distMatrix[ptB][ptA] = dist_AB\n",
    "    \n",
    "    #f(x): centers_setup\n",
    "    #PURPOSE: Randomly choose k tweets to be the initial centers of the cluster using their indices\n",
    "    #OUTPUT: The k indices of the centers \n",
    "    def centers_setup (self): \n",
    "        init_centers = self.tweets.sample(self.k, replace = False, weights = None, axis = 0).index\n",
    "        return np.array(init_centers)\n",
    "    \n",
    "    #f(x): cluster_setup\n",
    "    #PURPOSE: Once the centers have been assigned, initialize the clusters to that center\n",
    "    #OUTPUT: none\n",
    "    def cluster_setup (self): \n",
    "        \n",
    "        for tweet in self.tweets.Clean.index: \n",
    "            self.reverse_cluster[tweet] = -1 # initially each tweet has no cluster assigned to it\n",
    "        \n",
    "        for val in range(self.k):\n",
    "            self.clusters[val] = {self.init_centers[val]}\n",
    "\n",
    "            self.reverse_cluster[self.init_centers[val]] = self.init_centers[val]\n",
    "    #f(x): cluster_update\n",
    "    #PURPOSE: update the clusters based on who is closes to the new centers\n",
    "    #OUTPUT: the new clusters and their reverses \n",
    "    def cluster_update(self): \n",
    "        new_cluster = {}\n",
    "        new_rev_cluster = {}\n",
    "\n",
    "        for val in range(self.k): \n",
    "            new_cluster[val] = set()\n",
    "        for ptA in self.tweets.Clean.index: \n",
    "            min_distance =  np.inf\n",
    "            min_cluster = self.reverse_cluster[ptA] #min distance is current value\n",
    "            \n",
    "            #FIX THIS MINIMIZATION\n",
    "            for cluster in self.clusters:\n",
    "                counter = 0.00 \n",
    "                cluster_dist = []\n",
    "                for ptB in self.clusters: \n",
    "                    new_dist = self.distMatrix[ptA][ptB]\n",
    "                    #if the distance for that point to the specified cluster is lower than the current minimum point \n",
    "                    #then update the distance and assign it to that cluster instead of using an average metric\n",
    "                    counter += 1.00\n",
    "                    if counter >0.00: \n",
    "                        if min_distance > new_dist: \n",
    "                            min_distance = new_dist\n",
    "                            min_cluster = ptB\n",
    "            new_cluster[min_cluster].add(ptA)\n",
    "            new_rev_cluster[ptA] = min_cluster\n",
    "            \n",
    "        return new_cluster, new_rev_cluster\n",
    "   \n",
    "    def iteration(self):\n",
    "        rounds = 1\n",
    "        new_cluster, new_rev_cluster = self.cluster_update()\n",
    "        self.clusters = deepcopy(new_cluster)\n",
    "        self.reverse_cluster = deepcopy(new_rev_cluster)\n",
    "        \n",
    "        while rounds < self.iteration_threshold: \n",
    "            new_cluster = self.cluster_update()\n",
    "            rounds += 1\n",
    "            \n",
    "            if self.clusters != new_cluster: \n",
    "                self.clusters = deepcopy(new_cluster)\n",
    "                self.reverse_cluster = deepcopy(new_rev_cluster)\n",
    "                #self.center_update()\n",
    "            else: \n",
    "                return \n",
    "\n",
    "    def sse_calc(self):\n",
    "        sum_dist = 0.0\n",
    "        for center in self.clusters: \n",
    "            for pt in self.clusters[center]: \n",
    "                tmp_dist = self.distMatrix[center][pt]\n",
    "                sum_dist += tmp_dist**2\n",
    "        return sum_dist\n",
    "    \n",
    "    def cluster_print(self):\n",
    "        sse = self.sse_calc()\n",
    "        print(\"Sum Squared Distance/SSE: \", sse)\n",
    "        print(self.clusters) \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "9ab3c821",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31512\\4274743469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeansclusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretweets_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#kmeans.cluster_print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31512\\3329392389.py\u001b[0m in \u001b[0;36miteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mrounds\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration_threshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mnew_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mrounds\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31512\\3329392389.py\u001b[0m in \u001b[0;36mcluster_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0mcluster_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mptB\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                     \u001b[0mnew_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistMatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mptA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mptB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                     \u001b[1;31m#if the distance for that point to the specified cluster is lower than the current minimum point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[1;31m#then update the distance and assign it to that cluster instead of using an average metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 3\n",
    "\n",
    "kmeans = kmeansclusters(retweets_short, k)\n",
    "kmeans.iteration()\n",
    "print(kmeans.clusters)\n",
    "#kmeans.cluster_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475a05b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb27f5e8",
   "metadata": {},
   "source": [
    "## Works Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf12d4",
   "metadata": {},
   "source": [
    " * For loop to read all data files - https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    " \n",
    " * How to calculate Jaccard similarity - https://www.geeksforgeeks.org/how-to-calculate-jaccard-similarity-in-python/#\n",
    " \n",
    " * Cleaning and Tokenization of texts - https://www.kaggle.com/code/tariqsays/tweets-cleaning-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec6b85",
   "metadata": {},
   "source": [
    "path = r'C:\\Users\\teris\\ml_f23\\HW_3\\Tweets'  # or unix / linux / mac path\n",
    "\n",
    "# Get the files from the path provided in the OP\n",
    "files = Path(path).glob('*.txt')  # .rglob to get subdirectories\n",
    "\n",
    "dfs = list()\n",
    "for f in files:\n",
    "    print(f)\n",
    "    data = pd.read_table(f, sep = \"|\", header = None)\n",
    "    print(1)\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file'] = f.stem\n",
    "    print(2)\n",
    "    dfs.append(data)\n",
    "    print(3)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc069dc9",
   "metadata": {},
   "source": [
    "test_set1 = retweets.Clean[0] \n",
    "test_set2 = retweets.Clean[1]\n",
    "\n",
    "print(test_set1)\n",
    "print(test_set2)\n",
    "\n",
    "test_distance = jaccard_dist(test_set1, test_set2)\n",
    "print (test_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "        #f(x): cluster_update\n",
    "    #PURPOSE: update the clusters based on who is closes to the new centers\n",
    "    #OUTPUT: the new clusters and their reverses \n",
    "    def center_update(self): \n",
    "        new_cluster = {}\n",
    "        for group_name in self.clusters[0]:\n",
    "            distA = np.zeros(len(self.clusters[0][group_name]))\n",
    "            for ptA in self.clusters[0][group_name]:\n",
    "                print(cluster)\n",
    "                b_count = 0\n",
    "                for ptB in self.clusters[0][group_name]:\n",
    "                    distA[b_count] += self.distMatrix[ptA][ptB]\n",
    "                    b_count ++\n",
    "            #distA = np.empty(len(cluster[center])) \n",
    "            #for ptA in cluster[center]():\n",
    "                #print(ptA)\n",
    "                #b_count = 0 \n",
    "                #for ptB in cluster[center]:\n",
    "                    #distA[b_count] += self.distMatrix[ptA][ptB]\n",
    "                    #b_count += 1\n",
    "                #min_center = np.where(distA == min(distA))[0][0]\n",
    "                #new_cluster[center] = min_center #finds new center \n",
    "        #self.cluster = deepcopy(new_cluster)\n",
    "          \n",
    "        return\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
