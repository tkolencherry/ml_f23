{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375a38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ab8e3",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "* Drop tweet ID and timestamp\n",
    "* Change letters to all lowercase\n",
    "* Drop '#' and '@'\n",
    "* Drop URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44977a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585891883953496066</td>\n",
       "      <td>Wed Apr 08 19:48:05 +0000 2015</td>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585876545266286592</td>\n",
       "      <td>Wed Apr 08 18:47:08 +0000 2015</td>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585861945535791106</td>\n",
       "      <td>Wed Apr 08 17:49:07 +0000 2015</td>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585859917350731777</td>\n",
       "      <td>Wed Apr 08 17:41:03 +0000 2015</td>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585844465199407104</td>\n",
       "      <td>Wed Apr 08 16:39:39 +0000 2015</td>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                               1  \\\n",
       "0  585891883953496066  Wed Apr 08 19:48:05 +0000 2015   \n",
       "1  585876545266286592  Wed Apr 08 18:47:08 +0000 2015   \n",
       "2  585861945535791106  Wed Apr 08 17:49:07 +0000 2015   \n",
       "3  585859917350731777  Wed Apr 08 17:41:03 +0000 2015   \n",
       "4  585844465199407104  Wed Apr 08 16:39:39 +0000 2015   \n",
       "\n",
       "                                                   2  \n",
       "0  Are you a member of the network? Sign up here ...  \n",
       "1  What is palliative care like in India? One GP ...  \n",
       "2  Most viewed this week: I loved being a midwife...  \n",
       "3  How can technology improve mental health waiti...  \n",
       "4  In case you missed it: Why the #NHS shouldn’t ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the tweets from the various text files. Since we don't need to build our model based on originating news outlet, I combined the tweets into one text file\n",
    "#path = r'C:\\Users\\teris\\ml_f23\\HW_3\\tweets.txt'\n",
    "#tweets = pd.read_table(path, sep = \"|\", header = None, on_bad_lines='skip')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/tkolencherry/ml_f23/main/HW_3/tweets.txt\"\n",
    "file = requests.get(url).content\n",
    "tweets = pd.read_table(io.StringIO(file.decode('utf-8')), sep = \"|\", header = None, on_bad_lines = 'skip')\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f633aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  Are you a member of the network? Sign up here ...\n",
       "1  What is palliative care like in India? One GP ...\n",
       "2  Most viewed this week: I loved being a midwife...\n",
       "3  How can technology improve mental health waiti...\n",
       "4  In case you missed it: Why the #NHS shouldn’t ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now delete out the tweet id and timestamp\n",
    "retweets = tweets.drop(columns = [0,1]).drop_duplicates()\n",
    "retweets = retweets.rename(columns = {0:'ID', 2:'Tweet'})\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7772c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets['Clean'] = retweets.apply(lambda row: str(row['Tweet']).lower(),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(\"@[A-Za-z0-9_]+\",\"\", str(row['Clean'])),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(\"#\",\"\", str(row['Clean'])),axis=1) #we still want to keep the tagnames, just not the hashtag\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(r\"http\\S+\",\"\", row['Clean']),axis=1)\n",
    "retweets['Clean'] = retweets.apply(lambda row: re.sub(r\"www.\\S+\",\"\", row['Clean']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab71b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you a member of the network? Sign up here for free: https://register.theguardian.com/healthcare-professionals/ #NHS #healthcare\n",
      "are you a member of the network? sign up here for free:  nhs healthcare\n"
     ]
    }
   ],
   "source": [
    "print(retweets.Tweet[0])\n",
    "print(retweets.Clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3af386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'you', 'a', 'member', 'of', 'the', 'network?', 'sign', 'up', 'here', 'for', 'free:', 'nhs', 'healthcare']\n"
     ]
    }
   ],
   "source": [
    "#to make my life easier, I'm going to go ahead and pre-process the tweets to form their specific bag of words \n",
    "retweets['Clean'] = retweets.apply(lambda row: row['Clean'].split(),axis=1)\n",
    "print(retweets.Clean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54b4b4",
   "metadata": {},
   "source": [
    "## KMeans Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c27483b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you a member of the network? Sign up here ...</td>\n",
       "      <td>[are, you, a, member, of, the, network?, sign,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is palliative care like in India? One GP ...</td>\n",
       "      <td>[what, is, palliative, care, like, in, india?,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most viewed this week: I loved being a midwife...</td>\n",
       "      <td>[most, viewed, this, week:, i, loved, being, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can technology improve mental health waiti...</td>\n",
       "      <td>[how, can, technology, improve, mental, health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In case you missed it: Why the #NHS shouldn’t ...</td>\n",
       "      <td>[in, case, you, missed, it:, why, the, nhs, sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  Are you a member of the network? Sign up here ...   \n",
       "1  What is palliative care like in India? One GP ...   \n",
       "2  Most viewed this week: I loved being a midwife...   \n",
       "3  How can technology improve mental health waiti...   \n",
       "4  In case you missed it: Why the #NHS shouldn’t ...   \n",
       "\n",
       "                                               Clean  \n",
       "0  [are, you, a, member, of, the, network?, sign,...  \n",
       "1  [what, is, palliative, care, like, in, india?,...  \n",
       "2  [most, viewed, this, week:, i, loved, being, a...  \n",
       "3  [how, can, technology, improve, mental, health...  \n",
       "4  [in, case, you, missed, it:, why, the, nhs, sh...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_short = retweets.head(1000)\n",
    "retweets_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98a01a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeansclusters():\n",
    "    def __init__(self, tweets, k): \n",
    "        self.tweets = tweets\n",
    "        self.n = len(tweets)\n",
    "        self.k = k\n",
    "        self.distMatrix = {}\n",
    "        \n",
    "        self.clusters = {}\n",
    "        self.reverse_cluster = {}\n",
    "        self.cluster_avg = np.zeros(self.k)\n",
    "        \n",
    "        self.init_centers = self.centers_setup() #pick the random centers\n",
    "        #Set up the Jaccard matrix and the Initial Clusters\n",
    "        self.cluster_setup()\n",
    "        self.jaccard_matrix()\n",
    "        \n",
    "        self.iteration_threshold = 1000\n",
    "        \n",
    "    #f(x): jaccard_dist\n",
    "    #PURPOSE: find the jaccard distance ( 1 - jaccard similarity) between two sets of words\n",
    "    #OUTPUT: returns a float value between 0 and 1. The closer to 1, the further apart the sets are\n",
    "    def jaccard_dist(self, setA, setB): \n",
    "        setA = set(setA) #intersection and union won't work on lists, must be set format\n",
    "        setB = set(setB)\n",
    "        intersection_AB = len(setA.intersection(setB))\n",
    "        union_AB = len(setA.union(setB))\n",
    "        if union_AB == 0:\n",
    "            return 0.0\n",
    "        return 1 - (intersection_AB/union_AB)\n",
    "    \n",
    "    #f(x): jaccard_matrix\n",
    "    #PURPOSE: create a distance matrix where each tweet is a row and a column. This matrix will help us keep track of which two clusters are closest.\n",
    "            # This idea is similar to the matrices we used to show which nodes are connected in graphs.\n",
    "    #OUTPUT: none - the goal is simply to initialize the matrix\n",
    "    def jaccard_matrix (self):\n",
    "        for ptA in self.tweets.Clean.index: \n",
    "            self.distMatrix[ptA] = {}\n",
    "            setA = self.tweets.Clean[ptA]\n",
    "            for ptB in self.tweets.Clean.index: \n",
    "                if ptB not in self.distMatrix: \n",
    "                    self.distMatrix[ptB] = {}\n",
    "                setB = self.tweets.Clean[ptB]\n",
    "                dist_AB = self.jaccard_dist(setA, setB)\n",
    "                self.distMatrix[ptA][ptB] = dist_AB\n",
    "                self.distMatrix[ptB][ptA] = dist_AB\n",
    "    \n",
    "    #f(x): centers_setup\n",
    "    #PURPOSE: Randomly choose k tweets to be the initial centers of the cluster using their indices\n",
    "    #OUTPUT: The k indices of the centers \n",
    "    def centers_setup (self): \n",
    "        init_centers = self.tweets.sample(self.k, replace = False, weights = None, axis = 0).index\n",
    "        return np.array(init_centers)\n",
    "    \n",
    "    #f(x): cluster_setup\n",
    "    #PURPOSE: Once the centers have been assigned, initialize the clusters to that center\n",
    "    #OUTPUT: none\n",
    "    def cluster_setup (self): \n",
    "        \n",
    "        for tweet in self.tweets.Clean.index: \n",
    "            self.reverse_cluster[tweet] = -1 # initially each tweet has no cluster assigned to it\n",
    "        \n",
    "        for val in range(self.k):\n",
    "            self.clusters[val] = {self.init_centers[val]}\n",
    "\n",
    "            self.reverse_cluster[self.init_centers[val]] = self.init_centers[val]\n",
    "    #f(x): cluster_update\n",
    "    #PURPOSE: update the clusters based on who is closes to the new centers\n",
    "    #OUTPUT: the new clusters and their reverses \n",
    "    def cluster_update(self): \n",
    "        new_cluster = {}\n",
    "        new_rev_cluster = {}\n",
    "        total_cluster_dist = np.zeros(self.k)\n",
    "        for val in range(self.k): \n",
    "            new_cluster[val] = set()\n",
    "        for ptA in self.tweets.Clean.index: \n",
    "            min_distance =  np.inf\n",
    "            min_cluster = 0\n",
    "            #Fix this MINIMIZATION\n",
    "            for idx in range(len(self.init_centers)):                \n",
    "                ptB = self.init_centers[idx]\n",
    "                new_dist = self.distMatrix[ptA][ptB]\n",
    "                    #if the distance for that point to the specified cluster is lower than the current minimum point \n",
    "                    #then update the distance and assign it to that cluster instead of using an average metric\n",
    "                if min_distance > new_dist: \n",
    "                    min_distance = new_dist\n",
    "                    min_cluster = idx\n",
    "                \n",
    "            total_cluster_dist[min_cluster] += min_distance\n",
    "            new_cluster[min_cluster].add(ptA)\n",
    "            new_rev_cluster[ptA] = min_cluster\n",
    "            \n",
    "        for cluster in range(self.k): \n",
    "            cluster_length = int(len(self.clusters[cluster]))\n",
    "            self.cluster_avg[cluster] = total_cluster_dist[cluster]/cluster_length\n",
    "            \n",
    "        return new_cluster, new_rev_cluster\n",
    "    \n",
    "        #f(x): center_update \n",
    "    #PURPOSE: update the centroid of the clusters\n",
    "    #OUTPUT: the new centroid of the cluster\n",
    "    def center_update(self): \n",
    "        for group_name in self.clusters:\n",
    "            empty = set()\n",
    "            if self.clusters[group_name] != empty: \n",
    "                length = int(len(self.clusters[group_name]))\n",
    "                middle = total_cluster_dist[group_name]\n",
    "                #middle = int(np.median(sorted(self.clusters[group_name])))\n",
    "                self.init_centers[group_name] = middle\n",
    "        return\n",
    "        \n",
    "    def iteration(self):\n",
    "        rounds = 1\n",
    "        new_cluster, new_rev_cluster = self.cluster_update()\n",
    "        self.clusters = deepcopy(new_cluster)\n",
    "        self.reverse_cluster = deepcopy(new_rev_cluster)\n",
    "        while rounds < self.iteration_threshold: \n",
    "            new_cluster, new_rev_cluster  = self.cluster_update()\n",
    "            rounds += 1\n",
    "            if self.clusters != new_cluster: \n",
    "                self.clusters = deepcopy(new_cluster)\n",
    "                self.reverse_cluster = deepcopy(new_rev_cluster)\n",
    "                self.center_update()\n",
    "            else: \n",
    "                return \n",
    "\n",
    "    def sse_calc(self):\n",
    "        sum_dist = 0.0\n",
    "        for center in self.clusters: \n",
    "            for pt in self.clusters[center]: \n",
    "                tmp_dist = self.distMatrix[center][pt]\n",
    "                sum_dist += tmp_dist**2\n",
    "        return sum_dist\n",
    "    \n",
    "    def cluster_print(self):\n",
    "        sse = self.sse_calc()\n",
    "        print(\"Sum Squared Distance/SSE: \", sse)\n",
    "        for cluster in self.clusters: \n",
    "            print(\"Cluster \", cluster + 1, \" has \", len(self.clusters[cluster]),\" tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "326f2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  Clusters: \n",
      "Sum Squared Distance/SSE:  942.7039552910403\n",
      "Cluster  1  has  128  tweets.\n",
      "Cluster  2  has  642  tweets.\n",
      "Cluster  3  has  230  tweets.\n",
      "5  Clusters: \n",
      "Sum Squared Distance/SSE:  916.4211650435544\n",
      "Cluster  1  has  121  tweets.\n",
      "Cluster  2  has  484  tweets.\n",
      "Cluster  3  has  31  tweets.\n",
      "Cluster  4  has  211  tweets.\n",
      "Cluster  5  has  153  tweets.\n",
      "7  Clusters: \n",
      "Sum Squared Distance/SSE:  928.7367414845229\n",
      "Cluster  1  has  194  tweets.\n",
      "Cluster  2  has  411  tweets.\n",
      "Cluster  3  has  64  tweets.\n",
      "Cluster  4  has  46  tweets.\n",
      "Cluster  5  has  158  tweets.\n",
      "Cluster  6  has  59  tweets.\n",
      "Cluster  7  has  68  tweets.\n",
      "9  Clusters: \n",
      "Sum Squared Distance/SSE:  915.1228139931559\n",
      "Cluster  1  has  138  tweets.\n",
      "Cluster  2  has  87  tweets.\n",
      "Cluster  3  has  108  tweets.\n",
      "Cluster  4  has  7  tweets.\n",
      "Cluster  5  has  63  tweets.\n",
      "Cluster  6  has  30  tweets.\n",
      "Cluster  7  has  41  tweets.\n",
      "Cluster  8  has  338  tweets.\n",
      "Cluster  9  has  188  tweets.\n",
      "10  Clusters: \n",
      "Sum Squared Distance/SSE:  915.2370839534823\n",
      "Cluster  1  has  96  tweets.\n",
      "Cluster  2  has  18  tweets.\n",
      "Cluster  3  has  124  tweets.\n",
      "Cluster  4  has  142  tweets.\n",
      "Cluster  5  has  89  tweets.\n",
      "Cluster  6  has  37  tweets.\n",
      "Cluster  7  has  201  tweets.\n",
      "Cluster  8  has  75  tweets.\n",
      "Cluster  9  has  85  tweets.\n",
      "Cluster  10  has  133  tweets.\n"
     ]
    }
   ],
   "source": [
    "for k in [3,5, 7, 9, 10]:\n",
    "    print(k, \" Clusters: \")\n",
    "    kmeans = kmeansclusters(retweets_short, k)\n",
    "    kmeans.iteration()\n",
    "    kmeans.cluster_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2e540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49976d5",
   "metadata": {},
   "source": [
    "## Works Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cd86",
   "metadata": {},
   "source": [
    " * For loop to read all data files - https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    " \n",
    " * How to calculate Jaccard similarity - https://www.geeksforgeeks.org/how-to-calculate-jaccard-similarity-in-python/#\n",
    " \n",
    " * Cleaning and Tokenization of texts - https://www.kaggle.com/code/tariqsays/tweets-cleaning-with-python\n",
    " \n",
    " * One implementation of Jaccard k means - https://github.com/findkim/Jaccard-K-Means/blob/master/k-means%2B%2B.py\n",
    " \n",
    " * Another implementation of Jaccard kmeans - https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875 \n",
    " \n",
    " * How to Improve on the kmeans algorithm in the future - chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://repository.dinus.ac.id/docs/ajar/file_2013-09-26_09:38:06_Catur_Supriyanto,_M.CS__An_efficient_K-Means_Algorithm_integrated_with_Jaccard_Distance_Measure_for_Document_Clustering_-_Shameem,_Raihana_Ferdous_-_2009.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3bc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
